{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible demand features:\n",
    "- Hour of the day\n",
    "- day of the week\n",
    "- month\n",
    "- holiday indicator\n",
    "\n",
    "- temperature\n",
    "- precipitation\n",
    "\n",
    "- pick-up and drop-off locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from h3 import h3\n",
    "from dask import dataframe\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "ddf = dataframe.read_parquet(\"data/taxi_data_preprocessed.gzip\")\n",
    "ddf_weather = dataframe.read_parquet(\"data/prepared/weather_data_hourly_prepared.gzip\")\n",
    "\n",
    "#df = pd.read_parquet(\"data/taxi_data_preprocessed.gzip\")\n",
    "#df_weather = pd.read_parquet(\"data/prepared/weather_data_hourly_prepared.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddf = dataframe.from_pandas(df.head(10000), npartitions=20)\n",
    "#ddf_weather = dataframe.from_pandas(df_weather, npartitions=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = ddf.repartition(npartitions=20)\n",
    "ddf_weather = ddf_weather.repartition(npartitions=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate different Hexagons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "H3_HEXAGON_RESOLUTIONS = [3,6,9,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique pickup locations\n",
    "df_locations = ddf.pickup_centroid_location.unique().compute().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to geodataframe\n",
    "df_locations[\"pickup_centroid_location\"] = gpd.GeoSeries.from_wkt(df_locations[\"pickup_centroid_location\"])\n",
    "df_geo = gpd.GeoDataFrame(df_locations, geometry='pickup_centroid_location', crs=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hexagons with different resolutions\n",
    "for resolution in H3_HEXAGON_RESOLUTION:\n",
    "    df_geo[f\"h3_{resolution}\"] = df_geo.apply(lambda row: h3.geo_to_h3(row.pickup_centroid_location.y, row.pickup_centroid_location.x, resolution), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe the hexagons as an csv-file\n",
    "df_geo.to_csv(\"hexagons.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add and Adjust Data Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type\n",
    "ddf[\"trip_start_timestamp\"] = dataframe.to_datetime(ddf.trip_start_timestamp)\n",
    "ddf[\"trip_end_timestamp\"] = dataframe.to_datetime(ddf.trip_end_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns to taxi df\n",
    "ddf[\"hour\"] = ddf.trip_start_timestamp.dt.hour\n",
    "ddf[\"date\"] = ddf.trip_start_timestamp.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns to weather df\n",
    "ddf_weather[\"hour\"] = ddf_weather.time.dt.hour\n",
    "ddf_weather[\"date\"] = ddf_weather.time.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create timebins\n",
    "def create_timebins(ddf, steps):\n",
    "    for step in steps:\n",
    "        bins = list(range(0,25,step))\n",
    "        labels = range(len(bins)-1)\n",
    "        ddf[f\"time_bin_{step}\"] = ddf[\"hour\"].map_partitions(pd.cut, bins=bins,labels=labels, right=False, include_lowest=True)\n",
    "    return ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create timebin columns\n",
    "ddf = create_timebins(ddf, [1,2,6,24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add weekday and month columns\n",
    "ddf[\"weekday\"] = ddf.trip_start_timestamp.dt.weekday\n",
    "ddf[\"month\"] = ddf.trip_start_timestamp.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns\n",
    "ddf_features = ddf[[\"hour\", \"weekday\", \"time_bin_1\", \"time_bin_2\", \"time_bin_6\", \"time_bin_24\", \"month\", \"date\", \"pickup_census_tract\", \"pickup_centroid_location\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# join dfs\n",
    "ddf_features = ddf_features.merge(ddf_weather, on=[\"date\", \"hour\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data grouped by census tract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group using different timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_different_timebins_to_csv(ddf, time_steps, location_dimension):\n",
    "    for step in time_steps:  \n",
    "        df_grouped = (ddf.groupby(by=[\"date\", f\"time_bin_{step}\", location_dimension])\n",
    "         .agg({\n",
    "            \"time\": \"size\",\n",
    "            'relativehumidity_2m (%)': \"mean\",\n",
    "            \"temperature_2m (°C)\": \"mean\",\n",
    "            \"apparent_temperature (°C)\": \"mean\",\n",
    "            \"precipitation (mm)\": \"mean\",\n",
    "            \"cloudcover (%)\": \"mean\",\n",
    "            \"windspeed_10m (km/h)\": \"mean\",\n",
    "            \"weekday\": \"mean\",\n",
    "            \"month\": \"mean\"\n",
    "            }\n",
    "            )\n",
    "         .rename(columns={\"time\": \"ntrips\"})\n",
    "         .reset_index().compute()\n",
    "        )\n",
    "        df_grouped = df_grouped.dropna()\n",
    "        df_grouped.to_csv(f\"{location_dimension}_time_bin_{step}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by different timebins and census tracts\n",
    "group_by_different_timebins_to_csv(ddf_features, [1,2,6,24], \"pickup_census_tract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data grouped by H3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hexagons\n",
    "ddf_h3 = dataframe.read_csv(\"hexagons.csv\").drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_centroid_location</th>\n",
       "      <th>h3_3</th>\n",
       "      <th>h3_6</th>\n",
       "      <th>h3_9</th>\n",
       "      <th>h3_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: drop_by_shallow_copy, 2 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              pickup_centroid_location    h3_3    h3_6    h3_9   h3_12\n",
       "npartitions=1                                                         \n",
       "                                object  object  object  object  object\n",
       "                                   ...     ...     ...     ...     ...\n",
       "Dask Name: drop_by_shallow_copy, 2 tasks"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join hexagons\n",
    "ddf_features = ddf_features.merge(ddf_h3, on=\"pickup_centroid_location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    }
   ],
   "source": [
    "# group by different timebins and hexagon resolutions and save as csv\n",
    "for resolution in H3_HEXAGON_RESOLUTIONS:    \n",
    "    \n",
    "    # group data by time and location dimension\n",
    "    group_by_different_timebins_to_csv(ddf_features, [1,2,6,24], f\"h3_{resolution}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ddf.compute()\n",
    "df_weather = ddf_weather.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[[\"hour\", \"date\", \"pickup_census_tract\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df2.groupby(by=[\"date\", \"hour\", \"pickup_census_tract\"]).size().reset_index().rename(columns={0:\"trip_count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped[\"date\"] = pd.to_datetime(df_grouped[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped[\"month\"] = df_grouped.date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped[\"weekday\"] = df_grouped.date.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>pickup_census_tract</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>17031010202</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>17031010502</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>17031010702</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>17031020301</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>17031030300</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541393</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>23</td>\n",
       "      <td>17031841900</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541394</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>23</td>\n",
       "      <td>17031842200</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541395</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>23</td>\n",
       "      <td>17031842300</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541396</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>23</td>\n",
       "      <td>17031980000</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541397</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>23</td>\n",
       "      <td>17031980100</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>541398 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  hour  pickup_census_tract  trip_count  month  weekday\n",
       "0      2016-01-01     0          17031010202           1      1        4\n",
       "1      2016-01-01     0          17031010502           3      1        4\n",
       "2      2016-01-01     0          17031010702           2      1        4\n",
       "3      2016-01-01     0          17031020301           1      1        4\n",
       "4      2016-01-01     0          17031030300          17      1        4\n",
       "...           ...   ...                  ...         ...    ...      ...\n",
       "541393 2016-12-31    23          17031841900           3     12        5\n",
       "541394 2016-12-31    23          17031842200          18     12        5\n",
       "541395 2016-12-31    23          17031842300           9     12        5\n",
       "541396 2016-12-31    23          17031980000          18     12        5\n",
       "541397 2016-12-31    23          17031980100           4     12        5\n",
       "\n",
       "[541398 rows x 6 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.date = pd.to_datetime(df_weather.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = df_grouped.merge(df_weather, on=[\"date\", \"hour\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                         False\n",
       "hour                         False\n",
       "pickup_census_tract          False\n",
       "trip_count                   False\n",
       "month                        False\n",
       "weekday                      False\n",
       "time                         False\n",
       "temperature_2m (°C)          False\n",
       "relativehumidity_2m (%)      False\n",
       "apparent_temperature (°C)    False\n",
       "precipitation (mm)           False\n",
       "cloudcover (%)               False\n",
       "windspeed_10m (km/h)         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joined.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.to_csv(\"df_grouped_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ddf[[\"trip_start_timestamp\", \"time_bin_1\", \"hour\"]].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask Series Structure:\n",
      "npartitions=1\n",
      "    int64\n",
      "      ...\n",
      "dtype: int64\n",
      "Dask Name: reset_index, 709 tasks\n"
     ]
    }
   ],
   "source": [
    "# Group the data by hour and census tract, and count the number of trips in each group\n",
    "trip_counts = ddf.groupby([ddf[\"trip_start_timestamp\"].dt.date ,ddf['trip_start_timestamp'].dt.hour, 'pickup_census_tract']).size().reset_index('trip_count')\n",
    "\n",
    "# Print the resulting trip counts\n",
    "print(trip_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
