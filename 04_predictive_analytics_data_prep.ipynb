{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible demand features:\n",
    "- Hour of the day\n",
    "- day of the week\n",
    "- month\n",
    "- holiday indicator\n",
    "\n",
    "- temperature\n",
    "- precipitation\n",
    "\n",
    "- pick-up and drop-off locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from h3 import h3\n",
    "from dask import dataframe\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "ddf = dataframe.read_parquet(\"data/taxi_data_preprocessed.gzip\")\n",
    "ddf_weather = dataframe.read_parquet(\"data/prepared/weather_data_hourly_prepared.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = ddf.repartition(npartitions=20)\n",
    "ddf_weather = ddf_weather.repartition(npartitions=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate different Hexagons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "H3_HEXAGON_RESOLUTIONS = [1,2, 3,4,5,6,9,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique pickup locations\n",
    "df_locations = ddf.pickup_centroid_location.unique().compute().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to geodataframe\n",
    "df_locations[\"pickup_centroid_location\"] = gpd.GeoSeries.from_wkt(df_locations[\"pickup_centroid_location\"])\n",
    "df_geo = gpd.GeoDataFrame(df_locations, geometry='pickup_centroid_location', crs=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hexagons with different resolutions\n",
    "for resolution in H3_HEXAGON_RESOLUTIONS:\n",
    "    df_geo[f\"h3_{resolution}\"] = df_geo.apply(lambda row: h3.geo_to_h3(row.pickup_centroid_location.y, row.pickup_centroid_location.x, resolution), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe the hexagons as an csv-file\n",
    "df_geo.to_csv(\"hexagons.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add and Adjust Data Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type\n",
    "ddf[\"trip_start_timestamp\"] = dataframe.to_datetime(ddf.trip_start_timestamp)\n",
    "ddf[\"trip_end_timestamp\"] = dataframe.to_datetime(ddf.trip_end_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns to taxi df\n",
    "ddf[\"hour\"] = ddf.trip_start_timestamp.dt.hour\n",
    "ddf[\"date\"] = ddf.trip_start_timestamp.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns to weather df\n",
    "ddf_weather[\"hour\"] = ddf_weather.time.dt.hour\n",
    "ddf_weather[\"date\"] = ddf_weather.time.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create timebins\n",
    "def create_timebins(ddf, steps):\n",
    "    for step in steps:\n",
    "        bins = list(range(0,25,step))\n",
    "        labels = range(len(bins)-1)\n",
    "        ddf[f\"time_bin_{step}\"] = ddf[\"hour\"].map_partitions(pd.cut, bins=bins,labels=labels, right=False, include_lowest=True)\n",
    "    return ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create timebin columns\n",
    "ddf = create_timebins(ddf, [1,2,6,24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add weekday and month columns\n",
    "ddf[\"weekday\"] = ddf.trip_start_timestamp.dt.weekday\n",
    "ddf[\"month\"] = ddf.trip_start_timestamp.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns\n",
    "ddf_features = ddf[[\"hour\", \"weekday\", \"time_bin_1\", \"time_bin_2\", \"time_bin_6\", \"time_bin_24\", \"month\", \"date\", \"pickup_census_tract\", \"pickup_centroid_location\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# join dfs\n",
    "ddf_features = ddf_features.merge(ddf_weather, on=[\"date\", \"hour\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data grouped by census tract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group using different timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_different_timebins_to_csv(ddf, time_steps, location_dimension):\n",
    "    for step in time_steps:  \n",
    "        df_grouped = (ddf.groupby(by=[\"date\", f\"time_bin_{step}\", location_dimension])\n",
    "         .agg({\n",
    "            \"time\": \"size\",\n",
    "            'relativehumidity_2m (%)': \"mean\",\n",
    "            \"temperature_2m (°C)\": \"mean\",\n",
    "            \"apparent_temperature (°C)\": \"mean\",\n",
    "            \"precipitation (mm)\": \"mean\",\n",
    "            \"cloudcover (%)\": \"mean\",\n",
    "            \"windspeed_10m (km/h)\": \"mean\",\n",
    "            \"weekday\": \"mean\",\n",
    "            \"month\": \"mean\"\n",
    "            }\n",
    "            )\n",
    "         .rename(columns={\"time\": \"ntrips\"})\n",
    "         .reset_index().compute()\n",
    "        )\n",
    "        df_grouped = df_grouped.dropna()\n",
    "        df_grouped.to_csv(f\"{location_dimension}_time_bin_{step}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by different timebins and census tracts\n",
    "group_by_different_timebins_to_csv(ddf_features, [1,2,6,24], \"pickup_census_tract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data grouped by H3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hexagons\n",
    "ddf_h3 = dataframe.read_csv(\"hexagons.csv\").drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_centroid_location</th>\n",
       "      <th>h3_1</th>\n",
       "      <th>h3_2</th>\n",
       "      <th>h3_4</th>\n",
       "      <th>h3_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: drop_by_shallow_copy, 2 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              pickup_centroid_location    h3_1    h3_2    h3_4    h3_5\n",
       "npartitions=1                                                         \n",
       "                                object  object  object  object  object\n",
       "                                   ...     ...     ...     ...     ...\n",
       "Dask Name: drop_by_shallow_copy, 2 tasks"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join hexagons\n",
    "ddf_features = ddf_features.merge(ddf_h3, on=\"pickup_centroid_location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by different timebins and hexagon resolutions and save as csv\n",
    "for resolution in H3_HEXAGON_RESOLUTIONS:    \n",
    "    \n",
    "    # group data by time and location dimension\n",
    "    group_by_different_timebins_to_csv(ddf_features, [1,2,6,24], f\"h3_{resolution}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allow trip demand to be zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>time_bin_1</th>\n",
       "      <th>time_bin_2</th>\n",
       "      <th>time_bin_6</th>\n",
       "      <th>time_bin_24</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>pickup_census_tract</th>\n",
       "      <th>pickup_centroid_location</th>\n",
       "      <th>time</th>\n",
       "      <th>temperature_2m (°C)</th>\n",
       "      <th>relativehumidity_2m (%)</th>\n",
       "      <th>apparent_temperature (°C)</th>\n",
       "      <th>precipitation (mm)</th>\n",
       "      <th>cloudcover (%)</th>\n",
       "      <th>windspeed_10m (km/h)</th>\n",
       "      <th>h3_1</th>\n",
       "      <th>h3_2</th>\n",
       "      <th>h3_4</th>\n",
       "      <th>h3_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=20</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>category[known]</td>\n",
       "      <td>category[known]</td>\n",
       "      <td>category[known]</td>\n",
       "      <td>category[known]</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: merge_chunk, 1072 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                 hour weekday       time_bin_1       time_bin_2       time_bin_6      time_bin_24  month    date pickup_census_tract pickup_centroid_location            time temperature_2m (°C) relativehumidity_2m (%) apparent_temperature (°C) precipitation (mm) cloudcover (%) windspeed_10m (km/h)    h3_1    h3_2    h3_4    h3_5\n",
       "npartitions=20                                                                                                                                                                                                                                                                                                                            \n",
       "                int64   int64  category[known]  category[known]  category[known]  category[known]  int64  object               int64                   object  datetime64[ns]             float64                   int64                   float64            float64          int64              float64  object  object  object  object\n",
       "                  ...     ...              ...              ...              ...              ...    ...     ...                 ...                      ...             ...                 ...                     ...                       ...                ...            ...                  ...     ...     ...     ...     ...\n",
       "...               ...     ...              ...              ...              ...              ...    ...     ...                 ...                      ...             ...                 ...                     ...                       ...                ...            ...                  ...     ...     ...     ...     ...\n",
       "                  ...     ...              ...              ...              ...              ...    ...     ...                 ...                      ...             ...                 ...                     ...                       ...                ...            ...                  ...     ...     ...     ...     ...\n",
       "                  ...     ...              ...              ...              ...              ...    ...     ...                 ...                      ...             ...                 ...                     ...                       ...                ...            ...                  ...     ...     ...     ...     ...\n",
       "Dask Name: merge_chunk, 1072 tasks"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns\n",
    "ddf_features = ddf_features[[\"time\", \"hour\", \"weekday\", \"time_bin_1\", \"month\", \"date\", \"h3_5\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of trips\n",
    "df_trip_demand = ddf_features.groupby(by=[\"date\", \"time_bin_1\", \"h3_5\"])[\"time\"].size().to_frame().rename(columns={\"time\": \"ntrips\"}).reset_index().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns\n",
    "df_trip_demand[\"date\"] = pd.to_datetime(df_trip_demand.date)\n",
    "df_trip_demand[\"weekday\"] = df_trip_demand.date.dt.weekday\n",
    "df_trip_demand[\"month\"] = df_trip_demand.date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = ddf_weather.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather[\"date\"] = pd.to_datetime(df_weather.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join weather data\n",
    "df = df_trip_demand.merge(df_weather, left_on=[\"date\", \"time_bin_1\"], right_on=[\"date\", \"hour\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"h3_5_time_bin_1_zero.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
